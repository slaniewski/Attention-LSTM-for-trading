[logger]
LoggerLevel = 20
TensorboardLoggerPath = reports/tblogs

[data]
string_to_data_folder = dataLSTM

[raw]
IcsaRawDF = dataLSTM/raw/icsa.csv
CandleRawDF = dataLSTM/raw/rus.csv

[prep]
Stock = rus
DataPreprocessedDir = dataLSTM/preprocessed/
DataInputDir = dataLSTM/input/
DataOutputDir = dataLSTM/output/
ReportDir = reports/
ReportDirSummary = reports/summary/
VisualizationsDir = reports/figures/
FFilledIcsaDfPkl = dataLSTM/preprocessed/icsa_ffilled_{stock}.pkl
FFilledIcsaDfCsv = dataLSTM/preprocessed/icsa_ffilled_{stock}.csv
TisDfPkl = dataLSTM/preprocessed/tis_{stock}.pkl
TisDfCsv = dataLSTM/preprocessed/tis_{stock}.csv
JoinedDfPkl = dataLSTM/input/joined_{stock}.pkl
JoinedDfCsv = dataLSTM/input/joined_{stock}.csv
WindowSplitDict = dataLSTM/input/window_split_756_252_{stock}.pkl
PredictionsArray = dataLSTM/output/latest_preds_{stock}.pkl


[model]
;Seed = 1337
;
VarTarget = Target
; Features = Close
; Features = Open, High, Low, Close, Volume
Features = SMA5, SMA10, SMA50, EMA20, stoch5, ADOSC, MACDhist, WILLR, RSI, MOM, ROC, OBV, CCI, Open, High, Low, Close, Volume
; 
HyperParamTuneTrials = 8 
ModelsPerTrial = 1
; 
Lookback = 64
TrainWindow = 756 
;128
ValidationWindow = 252
TestWindow = 252 
;64
; 252 for years, 63 for more frequent updates
BatchSizeTrain = 63
BatchSizeValidation = 63
BatchSizeTest = 63
; 
Epochs = 100
; 
LSTMUnitsMin = 16
LSTMUnitsMax = 160
; 
HiddenLayersMin = 2
HiddenLayersMax = 3
; 
DropoutRateMin = 0.15
DropoutRateMax = 0.31
;
Regularization = 0.01, 0.04, 0.07, 0.1
; Loss functions -> available problems: {"regression", "classification"}
Problem = regression
LossFunctionRegression = MADL2
; MADL2
;  MSE  #MAPE #2.5e-4
LossMinDeltaMSE = 6.0e-5 
LossMinDeltaMape = 50
LossMinDeltaMADL = 5.0e-4 
LossFunctionClassification = binary_crossentropy
LossMinDeltaHinge = 0.03
LossMinDeltaBinaryCrossentropy = 0.00
ActivationFunction = tanh
; 
LearningRate = 0.0075, 0.005, 0.0025, 0.001 
; LearningRate = , 0.0001, 0.00001
; LearningRateDecay = 0.01
Optimizer = Adam, RMSprop
; , Adadelta
; AdamWeightDecay = 0.1
TargetThreshold = 0
; 0.001
PredictionThreshold = 0.00005

[evaluation]
TransactionCost = 0.001

; 0.005
; 0.0025
