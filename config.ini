[logger]
LoggerLevel = 20
TensorboardLoggerPath = reports/tblogs

[data]
string_to_data_folder = dataLSTM

[raw]
IcsaRawDF = dataLSTM/raw/icsa.csv
CandleRawDF = dataLSTM/raw/ndx.csv

[prep]
Stock = ndx
DataPreprocessedDir = dataLSTM/preprocessed/
DataInputDir = dataLSTM/input/
DataOutputDir = dataLSTM/output/
ReportDir = reports/
ReportDirSummary = reports/summary/
VisualizationsDir = reports/figures/
FFilledIcsaDfPkl = dataLSTM/preprocessed/icsa_ffilled_{stock}.pkl
FFilledIcsaDfCsv = dataLSTM/preprocessed/icsa_ffilled_{stock}.csv
TisDfPkl = dataLSTM/preprocessed/tis_{stock}.pkl
TisDfCsv = dataLSTM/preprocessed/tis_{stock}.csv
JoinedDfPkl = dataLSTM/input/joined_{stock}.pkl
JoinedDfCsv = dataLSTM/input/joined_{stock}.csv
WindowSplitDict = dataLSTM/input/window_split_756_252_{stock}.pkl
PredictionsArray = dataLSTM/output/latest_preds_{stock}.pkl


[model]
;Seed = 1337
;
VarTarget = Target
; Features = Close
; Features = Open, High, Low, Close, Volume
Features = SMA5, SMA10, SMA50, EMA20, stoch5, ADOSC, MACDhist, WILLR, RSI, MOM, ROC, OBV, CCI, Open, High, Low, Close, Volume
; 
HyperParamTuneTrials = 10
ModelsPerTrial = 1
; 
Lookback = 32
;64
TrainWindow = 756 
;126
ValidationWindow = 126
TestWindow = 126 
;64
; 252 for years, 63 for more frequent updates
BatchSizeTrain = 63
BatchSizeValidation = 63
BatchSizeTest = 63
; 
Epochs = 100
; 
LSTMUnitsMin = 16
LSTMUnitsMax = 176
; 
HiddenLayersMin = 2
HiddenLayersMax = 3
; 
DropoutRateMin = 0.07
DropoutRateMax = 0.31
;
Regularization = 0, 0.005, 0.01, 0.03
; Loss functions -> available problems: {"regression", "classification"}
Problem = regression
LossFunctionRegression = MSE
; MADL2
;  MSE  #MAPE #2.5e-4
LossMinDeltaMSE = 6.0e-5 
LossMinDeltaMape = 50
LossMinDeltaMADL = 5.0e-4 
LossMinDeltaPNL = 5.0e-4 
LossFunctionClassification = binary_crossentropy
LossMinDeltaHinge = 0.03
LossMinDeltaBinaryCrossentropy = 0.00
ActivationFunction = tanh
; 
LearningRate = 0.005, 0.0025, 0.001 
; LearningRate = , 0.0001, 0.00001, 0.0075,
; LearningRateDecay = 0.01
Optimizer = Adam, RMSprop
; , Adadelta
; AdamWeightDecay = 0.1
TargetThreshold = 0
; 0.001
PredictionThreshold = 0.00005

[evaluation]
TransactionCost = 0.0001

; 0.005
; 0.0025
